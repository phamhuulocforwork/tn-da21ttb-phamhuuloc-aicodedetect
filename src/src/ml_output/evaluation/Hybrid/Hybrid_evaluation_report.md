
# AI Code Detection Evaluation Report
## Method: Hybrid

### Summary Statistics
- **Total Samples**: 200
- **Correct Predictions**: 200
- **Overall Accuracy**: 100.00%

### Performance Metrics
- **Precision**: 1.000 (Of predicted AI, how many are actually AI)
- **Recall (Sensitivity)**: 1.000 (Of actual AI, how many detected)
- **F1-Score**: 1.000 (Harmonic mean of precision & recall)
- **Specificity**: 1.000 (Of actual Human, how many correctly identified)
- **Balanced Accuracy**: 1.000 (Average of sensitivity & specificity)

### Confidence Analysis
- **Average Confidence**: 0.803
- **Confidence Calibration**: 0.000 (How well confidence correlates with correctness)

### Confusion Matrix
```
                 Predicted
                AI    Human
Actual   AI     99       0
        Human    0     101
```

### Error Analysis
\n### Advanced Metrics\n- **AUC-ROC**: 1.000\n- **Average Precision**: 1.000\n